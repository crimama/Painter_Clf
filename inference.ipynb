{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2 \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from glob import glob \n",
    "from tqdm import tqdm \n",
    "import random \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "import utils\n",
    "from utils.Dataset import Data_loader,train_valid_split \n",
    "from utils import Model \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs = sorted(glob('./Data/test/*.jpg'))\n",
    "df = pd.read_csv('./Data/test.csv')\n",
    "\n",
    "class cfg:\n",
    "    img_size = 224 \n",
    "    batch_size = 16\n",
    "    train_ratio = 0.8 \n",
    "    num_epochs = 50 \n",
    "    num_fold = 1 \n",
    "    model_name = 'resnet50'\n",
    "    lr = 1e-3 \n",
    "    device = 'cuda:0'\n",
    "    sava_path = './Save_models/'\n",
    "\n",
    "def Data_init():\n",
    "    train_csv = pd.read_csv('./Data/train.csv')\n",
    "    img_dirs = np.array(sorted(glob('./Data/test/*.jpg')))\n",
    "    return img_dirs,train_csv\n",
    "\n",
    "img_dirs,train_csv = Data_init()\n",
    "label_decoder = {key:value for key,value in enumerate(np.unique(train_csv['artist']))}\n",
    "\n",
    "augmenter = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(size = (cfg.img_size,cfg.img_size)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "data = Data_loader(img_dirs,np.zeros(len(img_dirs)),cfg,augmenter=augmenter,shuffle=False)\n",
    "model_name = 'skfold_effb4/4_fold_best.pt'\n",
    "model = torch.load(f'./Save_models/{model_name}').to(cfg.device)\n",
    "model.eval()\n",
    "\n",
    "f_pred = [] \n",
    "with torch.no_grad():\n",
    "    for batch in (data):\n",
    "        x = torch.tensor(batch[0]).type(torch.float32).to(cfg.device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())\n",
    "f_result = [label_decoder[result] for result in f_pred ]\n",
    "\n",
    "\n",
    "submission = pd.read_csv('./Data/sample_submission.csv')\n",
    "submission['artist'] = f_result \n",
    "submission.to_csv(\"./submission/skfold_effb4.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
