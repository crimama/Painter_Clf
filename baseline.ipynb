{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2 \n",
    "import pandas as pd \n",
    "from glob import glob \n",
    "from tqdm import tqdm \n",
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from easydict import EasyDict as edict\n",
    "import json \n",
    "import cv2 \n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.models as models \n",
    "\n",
    "from utils import img_dset\n",
    "from utils.Dataset import Data_loader,train_valid_split,Data_init\n",
    "from utils.Augmentation import valid_augmenter,train_augmenter,dacon_augmenter\n",
    "from utils.Trainer import epoch_run,valid_epoch_run\n",
    "from utils import Model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "Train Loss : 3.7251438450168934 | Train F1 : 0.03173098684539334\n",
      "Valid Loss : 3.2596336570945947 | Valid F1 : 0.05114597874988134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [02:08<1:01:56, 128.15s/it]"
     ]
    }
   ],
   "source": [
    "cfg = edict({\n",
    "    'img_size' : 320,\n",
    "    'batch_size' :16 ,\n",
    "    'train_ratio' : 0.8, \n",
    "    'num_epochs' : 30, \n",
    "    'num_fold' : 5, \n",
    "    'model_name' : 'efficientnet_b4',\n",
    "    'lr' : 1e-4, \n",
    "    'device' : 'cuda:0',\n",
    "    'save_path' : './Save_models/skfold_effb4/',\n",
    "    'seed' : 41 ,\n",
    "    'crop_ratio' : 0.5 \n",
    "})\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True   \n",
    "\n",
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "    \n",
    "\n",
    "def Save_record(record):\n",
    "    save_record = pd.DataFrame(record)\n",
    "    save_record.columns = ['fold','epoch_loss','acc','epoch_val_loss','val_acc']\n",
    "    save_record.to_csv(f'{cfg.save_path}/record.csv',index=False)\n",
    "    \n",
    "\n",
    "seed_everything(cfg.seed) # Seed 고정\n",
    "record = [] \n",
    "img_dirs,labels = Data_init('./Data')\n",
    "for k,(train_index,valid_index) in enumerate(StratifiedKFold(n_splits=5).split(img_dirs,labels)):        \n",
    "    #데이터 로드 \n",
    "    if k == 0:\n",
    "        label_encoder = {value:key for key,value in enumerate(np.unique(labels))}\n",
    "    else:\n",
    "        img_dirs, labels = Data_init('./Data')\n",
    "    labels = pd.Series(labels).apply(lambda x : label_encoder[x]).values\n",
    "\n",
    "    #Train - Valid split \n",
    "    train_img_dirs, valid_img_dirs = img_dirs[train_index],img_dirs[valid_index]\n",
    "    train_labels, valid_labels = labels[train_index],labels[valid_index]\n",
    "    \n",
    "    #데이터셋, 데이터 로더 \n",
    "    train_loader = Data_loader(train_img_dirs,train_labels,cfg,augmenter=dacon_augmenter(cfg))\n",
    "    valid_loader = Data_loader(valid_img_dirs,valid_labels,cfg,augmenter=valid_augmenter(cfg),shuffle=False)\n",
    "    \n",
    "    #모델 config \n",
    "    model = Model(cfg.model_name,num_classes=len(np.unique(labels))).to(cfg.device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(cfg.device)\n",
    "    optimizer = torch.optim.RAdam(model.parameters(),lr=cfg.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=100,eta_min=0)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    print(f'Current Fold : {k}')\n",
    "    best = 0\n",
    "    for epoch in tqdm(range(cfg.num_epochs)):\n",
    "        epoch_loss,acc = epoch_run(train_loader,model,cfg.device,optimizer,criterion,scheduler,scaler)\n",
    "        epoch_loss_valid, acc_valid = valid_epoch_run(valid_loader,model,cfg.device,criterion)\n",
    "        print('\\nEpoch ', epoch)\n",
    "        print(f'Train Loss : {epoch_loss} | Train F1 : {acc}')\n",
    "        print(f'Valid Loss : {epoch_loss_valid} | Valid F1 : {acc_valid}')\n",
    "        record.append([k,epoch_loss,acc,epoch_loss_valid,acc_valid])\n",
    "        if epoch == 0:\n",
    "            best = acc_valid \n",
    "            if os.path.exists(cfg.save_path) == False:\n",
    "                os.mkdir(cfg.save_path)\n",
    "            else:\n",
    "                torch.save(model,cfg.save_path + f'{k}_fold_best.pt')\n",
    "        else:\n",
    "            if acc_valid > best:\n",
    "                torch.save(model,cfg.save_path + f'{k}_fold_best.pt')\n",
    "                print(f'Best_save{epoch}')\n",
    "\n",
    "df = pd.DataFrame(cfg.values()).T\n",
    "df.columns = cfg.keys() \n",
    "df.to_csv(f'{cfg.save_path}cfg.csv')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
